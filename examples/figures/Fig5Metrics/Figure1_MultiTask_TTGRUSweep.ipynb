{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import os\n",
    "from ctd.comparison.analysis.tt.tt import Analysis_TT \n",
    "from ctd.comparison.analysis.dd.dd import Analysis_DD\n",
    "# Import pca\n",
    "import dotenv\n",
    "from ctd.comparison.comparison import Comparison\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "dotenv.load_dotenv(dotenv.find_dotenv())\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/csverst/Github/CtDBenchmark/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "HOME_DIR = os.environ['HOME_DIR']\n",
    "print(HOME_DIR)\n",
    "\n",
    "pathTT = HOME_DIR + 'content/trained_models/task-trained/tt_MultiTask/'\n",
    "an_TT = Analysis_TT(run_name = \"TT\", filepath = pathTT)\n",
    "\n",
    "\n",
    "path_NODE_Sweep = pathTT + \"20250814_MultiTask_NODE_Sweep/\"\n",
    "subfolders_NODE = [f.path for f in os.scandir(path_NODE_Sweep) if f.is_dir()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = Comparison(comparison_tag=\"MultiTask_DDNODE_Sweep\")\n",
    "comparison.load_analysis(an_TT, reference_analysis=True, group = \"TT\")\n",
    "\n",
    "for subfolder in subfolders_NODE:\n",
    "    subfolder = subfolder + \"/\"\n",
    "    # Find int eh subfolder where latent_size is, and get the value after the = sign\n",
    "    # split the subfolder name\n",
    "    latent_size = subfolder.split(\"latent_size=\")[1].split(\"_\")[0]\n",
    "    # Make string with no decimals\n",
    "    \n",
    "    analysis_NODE = Analysis_DD.create(run_name = f\"NODE{latent_size}\", filepath = subfolder, model_type = \"SAE\")\n",
    "    comparison.load_analysis(analysis_NODE, group = f\"NODE{latent_size}\")\n",
    "\n",
    "comparison.regroup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Working on 1 of 23: NODE16\n",
      "State R2: 0.9108980298042297\n",
      "Rate R2: 0.6709356904029846\n",
      "Cycle Consistency R2: 1.0\n",
      "CO-BPS: 0.10703090578317642\n",
      "MMD: 0.20215243676826447\n",
      "\n",
      "Working on 2 of 23: NODE16\n",
      "State R2: 0.9028342962265015\n",
      "Rate R2: 0.6550465226173401\n",
      "Cycle Consistency R2: 0.7373210787773132\n",
      "CO-BPS: 0.10429887473583221\n",
      "MMD: 0.1631631397360039\n",
      "\n",
      "Working on 3 of 23: NODE16\n",
      "State R2: 0.8363466858863831\n",
      "Rate R2: 0.5836806893348694\n",
      "Cycle Consistency R2: 0.9441816806793213\n",
      "CO-BPS: 0.09435850381851196\n",
      "MMD: 0.20976081945539335\n",
      "\n",
      "Working on 4 of 23: NODE16\n",
      "State R2: 0.9099790453910828\n",
      "Rate R2: 0.6707605719566345\n",
      "Cycle Consistency R2: 1.0\n",
      "CO-BPS: 0.10674887150526047\n",
      "MMD: 0.21081298448932545\n",
      "\n",
      "Working on 5 of 23: NODE16\n",
      "State R2: 0.9109751582145691\n",
      "Rate R2: 0.6654043793678284\n",
      "Cycle Consistency R2: 1.0\n",
      "CO-BPS: 0.10609415173530579\n",
      "MMD: 0.18160434541300496\n",
      "\n",
      "Working on 6 of 23: NODE3\n",
      "State R2: 0.9167490005493164\n",
      "Rate R2: 0.32340162992477417\n",
      "Cycle Consistency R2: 1.0\n",
      "CO-BPS: 0.05306357890367508\n",
      "MMD: 0.4359888774149652\n",
      "\n",
      "Working on 7 of 23: NODE3\n",
      "State R2: 0.9325191378593445\n",
      "Rate R2: 0.3360324800014496\n",
      "Cycle Consistency R2: 1.0\n",
      "CO-BPS: 0.05535294488072395\n",
      "MMD: 0.43568111592334907\n",
      "\n",
      "Working on 8 of 23: NODE3\n",
      "State R2: 0.9277036190032959\n",
      "Rate R2: 0.3349683880805969\n",
      "Cycle Consistency R2: 1.0\n",
      "CO-BPS: 0.05508151277899742\n",
      "MMD: 0.43452691355891493\n",
      "\n",
      "Working on 9 of 23: NODE32\n",
      "State R2: 0.8824512362480164\n",
      "Rate R2: 0.7456936240196228\n",
      "Cycle Consistency R2: 0.7881314754486084\n",
      "CO-BPS: 0.11992435157299042\n",
      "MMD: 0.1521958041589235\n",
      "\n",
      "Working on 10 of 23: NODE32\n",
      "State R2: 0.8741699457168579\n",
      "Rate R2: 0.7298463582992554\n",
      "Cycle Consistency R2: 0.7805016040802002\n",
      "CO-BPS: 0.11745860427618027\n",
      "MMD: 0.15276299885396707\n",
      "\n",
      "Working on 11 of 23: NODE32\n",
      "State R2: 0.8631224036216736\n",
      "Rate R2: 0.732891857624054\n",
      "Cycle Consistency R2: 0.7873931527137756\n",
      "CO-BPS: 0.11872029304504395\n",
      "MMD: 0.16763919798104793\n",
      "\n",
      "Working on 12 of 23: NODE5\n",
      "State R2: 0.9320179224014282\n",
      "Rate R2: 0.4357282221317291\n",
      "Cycle Consistency R2: 1.0\n",
      "CO-BPS: 0.07285429537296295\n",
      "MMD: 0.3964659343821622\n",
      "\n",
      "Working on 13 of 23: NODE5\n",
      "State R2: 0.9029297828674316\n",
      "Rate R2: 0.3694716691970825\n",
      "Cycle Consistency R2: 1.0\n",
      "CO-BPS: 0.06257204711437225\n",
      "MMD: 0.41730990956515035\n",
      "\n",
      "Working on 14 of 23: NODE5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[43mcomparison\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetric_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstate_r2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrate_r2\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcycle_con\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mco-bps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmmd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle_con_var\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Github/CtDBenchmark/ctd/comparison/comparison.py:108\u001b[0m, in \u001b[0;36mComparison.compute_metrics\u001b[0;34m(self, ref_ind, metric_list, cycle_con_var)\u001b[0m\n\u001b[1;32m    104\u001b[0m n_input_neurons \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyses[i]\u001b[38;5;241m.\u001b[39mget_inputs()[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    105\u001b[0m inf_rates_train, inf_latents_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyses[i]\u001b[38;5;241m.\u001b[39mget_model_outputs(\n\u001b[1;32m    106\u001b[0m     phase\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    107\u001b[0m )\n\u001b[0;32m--> 108\u001b[0m inf_rates_val, inf_latents_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalyses\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_outputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m    \u001b[49m\u001b[43mphase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m    110\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m true_rates_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyses[i]\u001b[38;5;241m.\u001b[39mget_true_rates(phase\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    112\u001b[0m inp_spikes_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manalyses[i]\u001b[38;5;241m.\u001b[39mget_spiking(phase\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Github/CtDBenchmark/ctd/comparison/analysis/dd/dd.py:350\u001b[0m, in \u001b[0;36mAnalysis_DD_SAE.get_model_outputs\u001b[0;34m(self, phase)\u001b[0m\n\u001b[1;32m    348\u001b[0m dd_spiking \u001b[38;5;241m=\u001b[39m dd_spiking\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    349\u001b[0m dd_inputs \u001b[38;5;241m=\u001b[39m dd_inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 350\u001b[0m log_rates, latents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdd_spiking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdd_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mexp(log_rates), latents\n",
      "File \u001b[0;32m~/miniconda3/envs/ctdCuda12/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ctdCuda12/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Github/CtDBenchmark/ctd/data_modeling/models/SAE/node.py:82\u001b[0m, in \u001b[0;36mNODELatentSAE.forward\u001b[0;34m(self, data, inputs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, inputs):\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# Pass data through the model\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m     _, h_n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m     h_n \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;241m*\u001b[39mh_n], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     84\u001b[0m     h_n_drop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(h_n)\n",
      "File \u001b[0;32m~/miniconda3/envs/ctdCuda12/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ctdCuda12/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ctdCuda12/lib/python3.10/site-packages/torch/nn/modules/rnn.py:1133\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgru\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1134\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m   1137\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metrics = comparison.compute_metrics(metric_list=['state_r2', 'rate_r2','cycle_con', 'co-bps', 'mmd'], cycle_con_var=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = metrics['group']\n",
    "unique_groups = np.unique(groups)\n",
    "print(groups)\n",
    "print(unique_groups)\n",
    "# group_indices = [np.where(groups == group)[0] for group in unique_groups]\n",
    "colors1 = plt.cm.hsv(np.linspace(0, 1, len(unique_groups)+1))\n",
    "colors_list = []\n",
    "for i, group in enumerate(groups):\n",
    "    colors_list.append(colors1[np.where(unique_groups == group)[0][0]])\n",
    "    \n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(metrics['state_r2'], metrics['rate_r2'], c = colors_list)\n",
    "ax.set_xlabel(\"State R2\")\n",
    "ax.set_ylabel(\"Rate R2\")\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.plot([0, 1], [0, 1], 'r--')\n",
    "for legend_group in unique_groups:\n",
    "    ax.scatter([], [], c=colors1[np.where(unique_groups == legend_group)[0][0]], label=legend_group)\n",
    "ax.legend()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(metrics['cycle_con'], metrics['co-bps'], c = colors_list)\n",
    "ax.set_xlabel(\"Cycle Consistency\")\n",
    "ax.set_ylabel(\"CO-BPS\")\n",
    "ax.set_xlim([0, 1.1])\n",
    "ax.set_ylim([0, 0.15])\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.scatter(metrics['rate_r2'], metrics['mmd'], c = colors_list)\n",
    "ax.set_xlabel(\"Rate R2\")\n",
    "ax.set_ylabel(\"MMD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model0= 0\n",
    "model1 = 25\n",
    "model2 = 6\n",
    "\n",
    "trial_idx = 5\n",
    "neuron_idx = 53\n",
    "inputs1 = comparison.analyses[model0].get_inputs(phase = 'val')\n",
    "inputs2 = comparison.analyses[model1].get_inputs(phase = 'val')\n",
    "inputs3 = comparison.analyses[model2].get_inputs(phase = 'val')\n",
    "\n",
    "true_spikes = comparison.analyses[0].get_spiking(phase='val')\n",
    "\n",
    "timevec = np.linspace(0, 10, true_spikes.shape[1])\n",
    "bin_dur = timevec[1] - timevec[0]\n",
    "\n",
    "neurons_to_plot = 15\n",
    "timepoints_to_plot = 100\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "axes = fig.subplots(3, 1, sharey=True)\n",
    "ax = axes[0]\n",
    "ax.plot(inputs1[trial_idx,:timepoints_to_plot,0])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([])\n",
    "ax = axes[1]\n",
    "ax.plot(inputs1[trial_idx,:timepoints_to_plot,1])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([])\n",
    "ax = axes[2]\n",
    "ax.plot(inputs1[trial_idx,:timepoints_to_plot,2])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([])\n",
    "\n",
    "fig.suptitle(\"Inputs\")\n",
    "fig.savefig(\"input_plot.pdf\")\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "out_dict = comparison.analyses[comparison.ref_ind].get_model_outputs(phase = 'val')\n",
    "controlled = out_dict['controlled'].detach().cpu().numpy()\n",
    "axes = fig.subplots(3, 1, sharey=True)\n",
    "ax = axes[0]\n",
    "ax.plot(controlled[trial_idx,:timepoints_to_plot,0])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([])\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(controlled[trial_idx,:timepoints_to_plot,1])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([])\n",
    "\n",
    "ax = axes[2]\n",
    "ax.plot(controlled[trial_idx,:timepoints_to_plot,2])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.set_yticks([])\n",
    "ax.set_xticks([])\n",
    "fig.suptitle(\"Controlled\")\n",
    "fig.savefig(\"controlled_plot.pdf\")\n",
    "\n",
    "latents_to_plot = 15\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "out_dict = comparison.analyses[comparison.ref_ind].get_model_outputs(phase = 'val')\n",
    "latents = out_dict['latents'].detach().cpu().numpy()\n",
    "axes = fig.subplots(latents_to_plot, 1, sharey=True)\n",
    "for i in range(latents_to_plot):\n",
    "    ax = axes[latents_to_plot - i - 1]\n",
    "    ax.plot(latents[trial_idx,:timepoints_to_plot,i])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    # Remove the box\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "fig.suptitle(\"True OLatents\")\n",
    "fig.savefig(\"latents_plot.pdf\")\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "latents = comparison.analyses[model0].get_latents(phase = 'val').detach().cpu().numpy()\n",
    "axes = fig.subplots(latents_to_plot, 1, sharey=True)\n",
    "for i in range(latents_to_plot):\n",
    "    ax = axes[latents_to_plot - i - 1]\n",
    "    ax.plot(latents[trial_idx,:timepoints_to_plot,i])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    # Remove the box\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "fig.suptitle(\"Model 0 Latents\")\n",
    "fig.savefig(\"latents_plot_model0.pdf\")\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(5,neurons_to_plot/2))\n",
    "ax = fig.add_subplot(111)\n",
    "# Plot a raster plot of all the spikes\n",
    "trial_spikes = true_spikes[trial_idx]\n",
    "for i in range(neurons_to_plot):\n",
    "    neuron_spikes = trial_spikes[:,i]\n",
    "    for j in range(timepoints_to_plot):\n",
    "        spikes = neuron_spikes[j]\n",
    "        if spikes >0:\n",
    "            spike_times = random.uniform(timevec[j], timevec[j]+ bin_dur, int(spikes))\n",
    "            for spike_time in spike_times:\n",
    "                ax.plot([spike_time, spike_time], [i, i+0.8], color='k', linewidth=0.4)\n",
    "fig.suptitle(\"True Spikes\")\n",
    "fig.savefig(\"raster_plot.pdf\")\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "axes = fig.subplots(neurons_to_plot, 1, sharey=True)\n",
    "rates1 = comparison.analyses[model0].get_rates(phase = 'val').detach().cpu().numpy()\n",
    "for i in range(neurons_to_plot):\n",
    "    ax = axes[neurons_to_plot - i - 1]\n",
    "    if i >9:\n",
    "        ax.plot(rates1[trial_idx,:timepoints_to_plot,i], color ='r')\n",
    "    else:\n",
    "        ax.plot(rates1[trial_idx,:timepoints_to_plot,i], color ='k')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    # Remove the box\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "fig.suptitle(\"Model 0 Inferred Rates\")\n",
    "fig.savefig(\"rates_plot.pdf\")\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "axes = fig.subplots(neurons_to_plot, 1, sharey=True)\n",
    "true_rates1 = comparison.analyses[model0].get_true_rates(phase = 'val').detach().cpu().numpy()\n",
    "for i in range(neurons_to_plot):\n",
    "    ax = axes[neurons_to_plot - i - 1]\n",
    "    if i >9:\n",
    "        ax.plot(true_rates1[trial_idx,:timepoints_to_plot,i], color ='r')\n",
    "    else:\n",
    "        ax.plot(true_rates1[trial_idx,:timepoints_to_plot,i], color ='k')\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    # Remove the box\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticks([])\n",
    "fig.suptitle(\"Model 0 True Rates\")\n",
    "fig.savefig(\"true_rates_plot.pdf\")\n",
    "\n",
    "    # ax.set_xlim([0, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "use_neuron_trial = True\n",
    "\n",
    "model0= 0\n",
    "model1 = 25\n",
    "model2 = 6\n",
    "\n",
    "trial_idx = 5\n",
    "neuron_idx = 53\n",
    "\n",
    "def bits_per_spike_per_neuron_trial(preds, targets):\n",
    "    \"\"\"\n",
    "    Computes BPS for each neuron and each trial, reducing along the time dimension.\n",
    "    Preds are logrates and targets are binned spike counts.\n",
    "    Inputs are expected to be n_trials x n_timesteps x n_neurons arrays.\n",
    "    \"\"\"\n",
    "    # Compute NLL for model predictions along the time dimension\n",
    "    nll_model = F.poisson_nll_loss(preds, targets, full=True, log_input=True, reduction=\"none\")\n",
    "    nll_model = torch.sum(nll_model, dim=1)  # Sum over the time dimension (n_timesteps)\n",
    "    \n",
    "    # Compute the mean firing rate (null model) for each neuron and trial\n",
    "    mean_targets = torch.mean(targets, dim=1, keepdim=True)\n",
    "    \n",
    "    # Compute NLL for the null model\n",
    "    nll_null = F.poisson_nll_loss(\n",
    "        mean_targets.expand_as(targets),  # Broadcast the mean target to match the shape of preds/targets\n",
    "        targets,\n",
    "        log_input=False,\n",
    "        full=True,\n",
    "        reduction=\"none\"\n",
    "    )\n",
    "    nll_null = torch.sum(nll_null, dim=1)  # Sum over the time dimension\n",
    "    \n",
    "    # Compute bits per spike for each trial and each neuron\n",
    "    bps = (nll_null - nll_model) / torch.nansum(targets, dim=1) / math.log(2)\n",
    "    \n",
    "    return bps  # Returns a tensor of shape (n_trials, n_neurons)\n",
    "\n",
    "\n",
    "\n",
    "true_spikes = comparison.analyses[0].get_spiking(phase='val')\n",
    "true_rates = comparison.analyses[0].get_true_rates(phase='val')\n",
    "rates1 = comparison.analyses[model0].get_rates(phase='val').detach().cpu().numpy()\n",
    "rates2 = comparison.analyses[model1].get_rates(phase='val').detach().cpu().numpy()\n",
    "rates3 = comparison.analyses[model2].get_rates(phase='val').detach().cpu().numpy()\n",
    "trial_spikes = true_spikes[trial_idx, :,neuron_idx]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(4, 3))\n",
    "timevec = np.linspace(0, 10, true_spikes.shape[1])\n",
    "bin_dur = timevec[1] - timevec[0]\n",
    "ax3 = fig.add_subplot(111)\n",
    "ax3.plot(timevec, true_rates[trial_idx, :, neuron_idx], color = 'k', label = \"True Rate\")\n",
    "ax3.plot(timevec, rates1[trial_idx, :, neuron_idx], label = comparison.analyses[model0].run_name)\n",
    "ax3.plot(timevec, rates2[trial_idx, :, neuron_idx], label = comparison.analyses[model1].run_name)\n",
    "ax3.plot(timevec, rates3[trial_idx, :, neuron_idx], label = comparison.analyses[model2].run_name)\n",
    "\n",
    "\n",
    "r1 = torch.Tensor(rates1[trial_idx, :, neuron_idx])\n",
    "r2 = torch.Tensor(rates2[trial_idx, :, neuron_idx])\n",
    "r3 = torch.Tensor(rates3[trial_idx, :, neuron_idx])\n",
    "t_spikes = torch.Tensor(true_spikes[trial_idx, :, neuron_idx])\n",
    "\n",
    "if use_neuron_trial:\n",
    "    bps_1 = bits_per_spike_per_neuron_trial(torch.log(torch.Tensor(rates1)), torch.Tensor(true_spikes))[trial_idx, neuron_idx]\n",
    "    bps_2 = bits_per_spike_per_neuron_trial(torch.log(torch.Tensor(rates2)), torch.Tensor(true_spikes))[trial_idx, neuron_idx]\n",
    "    bps_3 = bits_per_spike_per_neuron_trial(torch.log(torch.Tensor(rates3)), torch.Tensor(true_spikes))[trial_idx, neuron_idx]\n",
    "    r2_1 = r2_score(true_rates[trial_idx, :, neuron_idx], rates1[trial_idx, :, neuron_idx])\n",
    "    r2_2 = r2_score(true_rates[trial_idx, :, neuron_idx], rates2[trial_idx, :, neuron_idx])\n",
    "    r2_3 = r2_score(true_rates[trial_idx, :, neuron_idx], rates3[trial_idx, :, neuron_idx])\n",
    "else:\n",
    "    bps_1 = metrics['co-bps'][model0]\n",
    "    bps_2 = metrics['co-bps'][model1]\n",
    "    bps_3 = metrics['co-bps'][model2]\n",
    "\n",
    "    r2_1 = metrics['rate_r2'][model0]\n",
    "    r2_2 = metrics['rate_r2'][model1]\n",
    "    r2_3 = metrics['rate_r2'][model2]\n",
    "\n",
    "for i, spike in enumerate(trial_spikes):\n",
    "    if spike > 0:\n",
    "        spike_times = np.linspace(timevec[i], timevec[i] + bin_dur, int(spike)+2)\n",
    "        spike_times = spike_times[1:-1]\n",
    "        for spike_time in spike_times:\n",
    "            ax3.plot([spike_time, spike_time], [3, 3.5], color='k', linewidth=0.2)\n",
    "ax3.legend()\n",
    "ax3.set_xlim([0, 4])\n",
    "\n",
    "fig.suptitle(f\"R2: {r2_1:.2f}, {r2_2:.2f}, {r2_3:.2f} BPS: {bps_1:.3f}, {bps_2:.3f}, {bps_3:.3f}\")\n",
    "plt.savefig(\"spikes.pdf\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lats = 256\n",
    "min_lats = 3\n",
    "opacity = np.zeros(len(comparison.analyses))\n",
    "latent_sizes = []\n",
    "for i, analysis in enumerate(comparison.analyses):\n",
    "    # Get the latent size (in run name after \"GRU\")\n",
    "    print(i)\n",
    "    if analysis.run_name.__contains__(\"NODE\"):\n",
    "        latent_size = int(analysis.run_name.split(\"NODE\")[1])\n",
    "        # Make an opacity based on the log10 of latent size\n",
    "        opacity[i] = latent_size / max_lats\n",
    "        latent_sizes.append(latent_size)\n",
    "        print(analysis.run_name, latent_size, opacity[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def reconstruct_latents(lin_reg_model, N_pred, variance_threshold=0.01):\n",
    "    \"\"\"\n",
    "    Reconstructs the latent variables from predicted log-rates using the pseudoinverse of the readout matrix,\n",
    "    applying singular value thresholding.\n",
    "\n",
    "    Parameters:\n",
    "    lin_reg_model (LinearRegression): Trained LinearRegression model mapping latents to log-rates.\n",
    "    N_pred (numpy.ndarray): Predicted log-rates, shape (n_samples, n_neurons).\n",
    "    variance_threshold (float): Threshold for cumulative variance to retain.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Reconstructed latent variables, shape (n_samples, n_latents).\n",
    "    \"\"\"\n",
    "    # Extract the estimated readout matrix (coefficients) and intercept\n",
    "    W_hat = lin_reg_model.coef_        # Shape: (n_neurons, n_latents)\n",
    "    b_hat = lin_reg_model.intercept_   # Shape: (n_neurons,)\n",
    "\n",
    "    # Ensure N_pred is a 2D array\n",
    "    if N_pred.ndim == 1:\n",
    "        N_pred = N_pred.reshape(-1, 1)\n",
    "\n",
    "    # Subtract the intercept from the predicted log-rates\n",
    "    N_centered = N_pred - b_hat        # Shape: (n_samples, n_neurons)\n",
    "\n",
    "    # Perform SVD on W_hat\n",
    "    U, Sigma, Vt = np.linalg.svd(W_hat, full_matrices=False)  # W_hat = U @ diag(Sigma) @ Vt\n",
    "\n",
    "    # Compute normalized squared singular values (variance explained)\n",
    "    normalized_variance = (Sigma ** 2) / np.sum(Sigma ** 2)\n",
    "\n",
    "    # Compute cumulative variance\n",
    "    cumulative_variance = np.cumsum(normalized_variance)\n",
    "\n",
    "    # Determine number of components to retain to capture desired variance\n",
    "    num_components = np.searchsorted(cumulative_variance, (1 - variance_threshold)) + 1\n",
    "\n",
    "    # Ensure num_components does not exceed total number of components\n",
    "    num_components = min(num_components, len(Sigma))\n",
    "\n",
    "    # Truncate the singular values and corresponding matrices\n",
    "    U_trunc = U[:, :num_components]           # Shape: (n_neurons, num_components)\n",
    "    Sigma_trunc = Sigma[:num_components]      # Shape: (num_components,)\n",
    "    Vt_trunc = Vt[:num_components, :]         # Shape: (num_components, n_latents)\n",
    "\n",
    "    # Compute the truncated pseudoinverse\n",
    "    Sigma_inv_trunc = np.diag(1 / Sigma_trunc)  # Shape: (num_components, num_components)\n",
    "    W_pinv_trunc = Vt_trunc.T @ Sigma_inv_trunc @ U_trunc.T  # Shape: (n_latents, n_neurons)\n",
    "\n",
    "    # Reconstruct the latent variables\n",
    "    L_hat = N_centered @ W_pinv_trunc.T     # Shape: (n_samples, n_latents)\n",
    "\n",
    "    return L_hat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "target_run_names = {\"NODE3\", \"NODE8\", \"NODE64\"}\n",
    "first_occurrences = {}\n",
    "\n",
    "for i, an in enumerate(comparison.analyses):\n",
    "    if an.run_name in target_run_names and an.run_name not in first_occurrences:\n",
    "        first_occurrences[an.run_name] = i\n",
    "\n",
    "print(first_occurrences)\n",
    "model3= first_occurrences['NODE3']\n",
    "model8 = first_occurrences['NODE8'] \n",
    "model64 = first_occurrences['NODE64'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3= first_occurrences['NODE3']\n",
    "model8 = first_occurrences['NODE8'] \n",
    "model64 = first_occurrences['NODE64'] \n",
    "\n",
    "print(comparison.analyses[model3].run_name)\n",
    "print(comparison.analyses[model8].run_name)\n",
    "print(comparison.analyses[model64].run_name)\n",
    "# Get the true latents (train and val)\n",
    "out_dict = comparison.analyses[comparison.ref_ind].get_model_outputs(phase = 'train')\n",
    "true_latents = out_dict['latents'].detach().cpu().numpy()\n",
    "out_val = comparison.analyses[comparison.ref_ind].get_model_outputs(phase = 'val')\n",
    "true_latents_val = out_val['latents'].detach().cpu().numpy()\n",
    "\n",
    "# Get the latents and rates for the models\n",
    "model1_lats_train = comparison.analyses[model3].get_latents(phase = 'train').detach().cpu().numpy()\n",
    "model2_lats_train = comparison.analyses[model8].get_latents(phase = 'train').detach().cpu().numpy()\n",
    "model3_lats_train = comparison.analyses[model64].get_latents(phase = 'train').detach().cpu().numpy()\n",
    "\n",
    "model1_lats_val = comparison.analyses[model3].get_latents(phase = 'val').detach().cpu().numpy()\n",
    "model2_lats_val = comparison.analyses[model8].get_latents(phase = 'val').detach().cpu().numpy()\n",
    "model3_lats_val = comparison.analyses[model64].get_latents(phase = 'val').detach().cpu().numpy()\n",
    "\n",
    "model1_rates_train = np.log(comparison.analyses[model3].get_rates(phase = 'train').detach().cpu().numpy())\n",
    "model2_rates_train = np.log(comparison.analyses[model8].get_rates(phase = 'train').detach().cpu().numpy())\n",
    "model3_rates_train = np.log(comparison.analyses[model64].get_rates(phase = 'train').detach().cpu().numpy())\n",
    "\n",
    "model1_rates_val = np.log(comparison.analyses[model3].get_rates(phase = 'val').detach().cpu().numpy())\n",
    "model2_rates_val = np.log(comparison.analyses[model8].get_rates(phase = 'val').detach().cpu().numpy())\n",
    "model3_rates_val = np.log(comparison.analyses[model64].get_rates(phase = 'val').detach().cpu().numpy())\n",
    "\n",
    "# Get the number of trials, timesteps and latents\n",
    "n_trials_train, n_timesteps, n_latents = true_latents.shape\n",
    "n_trials_val = true_latents_val.shape[0]\n",
    "\n",
    "# Get the PCA space for latents on the training set\n",
    "pca1= PCA()\n",
    "pca2= PCA()\n",
    "pca3= PCA()\n",
    "\n",
    "model1_lats_pca_train_flat = pca1.fit_transform(model1_lats_train.reshape(-1, model1_lats_train.shape[-1]))\n",
    "model2_lats_pca_train_flat = pca2.fit_transform(model2_lats_train.reshape(-1, model2_lats_train.shape[-1]))\n",
    "model3_lats_pca_train_flat = pca3.fit_transform(model3_lats_train.reshape(-1, model3_lats_train.shape[-1]))\n",
    "\n",
    "model1_lats_pca_val_flat = pca1.transform(model1_lats_val.reshape(-1, model1_lats_val.shape[-1]))\n",
    "model2_lats_pca_val_flat = pca2.transform(model2_lats_val.reshape(-1, model2_lats_val.shape[-1]))\n",
    "model3_lats_pca_val_flat = pca3.transform(model3_lats_val.reshape(-1, model3_lats_val.shape[-1]))\n",
    "\n",
    "\n",
    "# Get the PCA space for rates on the training set\n",
    "pca_r1 = PCA()\n",
    "pca_r2 = PCA()\n",
    "pca_r3 = PCA()\n",
    "\n",
    "model1_rates_pca_train_flat = pca_r1.fit_transform(model1_rates_train.reshape(-1, model1_rates_train.shape[-1]))\n",
    "model2_rates_pca_train_flat = pca_r2.fit_transform(model2_rates_train.reshape(-1, model2_rates_train.shape[-1]))\n",
    "model3_rates_pca_train_flat = pca_r3.fit_transform(model3_rates_train.reshape(-1, model3_rates_train.shape[-1]))\n",
    "\n",
    "model1_rates_pca_val_flat = pca_r1.transform(model1_rates_val.reshape(-1, model1_rates_val.shape[-1]))\n",
    "model2_rates_pca_val_flat = pca_r2.transform(model2_rates_val.reshape(-1, model2_rates_val.shape[-1]))\n",
    "model3_rates_pca_val_flat = pca_r3.transform(model3_rates_val.reshape(-1, model3_rates_val.shape[-1]))\n",
    "\n",
    "# Fit a linear regression model to map the PCA space of latents to the PCA space of rates\n",
    "model1_readout = LinearRegression()\n",
    "model2_readout = LinearRegression()\n",
    "model3_readout = LinearRegression()\n",
    "\n",
    "model1_readout.fit(model1_lats_pca_train_flat, model1_rates_pca_train_flat)\n",
    "model2_readout.fit(model2_lats_pca_train_flat, model2_rates_pca_train_flat)\n",
    "model3_readout.fit(model3_lats_pca_train_flat, model3_rates_pca_train_flat)\n",
    "\n",
    "# Reconstruct the latents from the rates using the readout matrix and singular value thresholding\n",
    "recon_latents_1 = reconstruct_latents(model1_readout, model1_rates_pca_train_flat, variance_threshold=0.01)\n",
    "recon_latents_2 = reconstruct_latents(model2_readout, model2_rates_pca_train_flat, variance_threshold=0.01)\n",
    "recon_latents_3 = reconstruct_latents(model3_readout, model3_rates_pca_train_flat, variance_threshold=0.01)\n",
    "\n",
    "pred2_cc_trials = recon_latents_2.reshape(n_trials_train, n_timesteps, -1)\n",
    "pred3_cc_trials = recon_latents_3.reshape(n_trials_train, n_timesteps, -1)\n",
    "\n",
    "# Fit a linear regression model to map the true latents to the PCA space of latents\n",
    "lm2 = LinearRegression()\n",
    "lm3 = LinearRegression()\n",
    "\n",
    "lm2.fit(true_latents.reshape(-1, true_latents.shape[-1]), model2_lats_pca_train_flat)\n",
    "lm3.fit(true_latents.reshape(-1, true_latents.shape[-1]), model3_lats_pca_train_flat)\n",
    "\n",
    "predInf_from_True2 = lm2.predict(true_latents_val.reshape(-1, true_latents_val.shape[-1]))\n",
    "predInf_from_True3 = lm3.predict(true_latents_val.reshape(-1, true_latents_val.shape[-1]))\n",
    "\n",
    "\n",
    "stateR2_2 = r2_score(model2_lats_pca_val_flat, predInf_from_True2, multioutput='raw_values')\n",
    "stateR2_3 = r2_score(model3_lats_pca_val_flat, predInf_from_True3, multioutput='raw_values')\n",
    "\n",
    "stateR2_2_VAF = r2_score(model2_lats_pca_val_flat, predInf_from_True2, multioutput='variance_weighted')\n",
    "stateR2_3_VAF = r2_score(model3_lats_pca_val_flat, predInf_from_True3, multioutput='variance_weighted')\n",
    "\n",
    "pred2_trials = predInf_from_True2.reshape(n_trials_val, n_timesteps, -1)\n",
    "pred3_trials = predInf_from_True3.reshape(n_trials_val, n_timesteps, -1)\n",
    "\n",
    "model2_pcs_trial = model2_lats_pca_val_flat.reshape(n_trials_val, n_timesteps, -1)\n",
    "model3_pcs_trial = model3_lats_pca_val_flat.reshape(n_trials_val, n_timesteps, -1)\n",
    "\n",
    "ccR2_2 = r2_score(pred2_cc_trials.reshape(-1, pred2_cc_trials.shape[-1]), model2_lats_pca_train_flat, multioutput='raw_values')\n",
    "ccR2_3 = r2_score(pred3_cc_trials.reshape(-1, pred3_cc_trials.shape[-1]), model3_lats_pca_train_flat, multioutput='raw_values')\n",
    "\n",
    "ccR2_2_VAF = r2_score(pred2_cc_trials.reshape(-1, pred2_cc_trials.shape[-1]), model2_lats_pca_train_flat, multioutput='variance_weighted')\n",
    "ccR2_3_VAF = r2_score(pred3_cc_trials.reshape(-1, pred3_cc_trials.shape[-1]), model3_lats_pca_train_flat, multioutput='variance_weighted')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"State R2: {stateR2_2}, {stateR2_3}\")\n",
    "print(f\"State R2 VAF: {stateR2_2_VAF}, {stateR2_3_VAF}\")\n",
    "# print(f\"Cycle Consistency R2: {ccR2_2}, {ccR2_3}\")\n",
    "print(f\"Cycle Consistency R2 VAF: {ccR2_2_VAF}, {ccR2_3_VAF}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hide_splines(axIn):\n",
    "    axIn.spines['top'].set_visible(False)\n",
    "    axIn.spines['right'].set_visible(False)\n",
    "    axIn.spines['left'].set_visible(False)\n",
    "    axIn.spines['bottom'].set_visible(False)\n",
    "    axIn.set_yticks([])\n",
    "    axIn.set_xticks([])\n",
    "\n",
    "latent_dim = 7\n",
    "trial_num =5\n",
    "n_timesteps= 500\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(211)\n",
    "ax.plot(model2_pcs_trial[trial_num, :n_timesteps, latent_dim], c = 'green', label = comparison.analyses[model8].run_name)\n",
    "ax.plot(pred2_trials[trial_num, :n_timesteps, latent_dim], c = 'lightgreen', label = f\"Pred {comparison.analyses[model8].run_name}\")\n",
    "ax.plot(pred2_cc_trials[trial_num, :n_timesteps, latent_dim], c = 'darkgreen', label = f\"Pred CC {comparison.analyses[model8].run_name}\")\n",
    "# ax.set_title(f\"State R2: {stateR2_2[latent_dim]:.2f}, CC R2: {ccR2_2[latent_dim]:.2f}\")\n",
    "ax.set_title(f\"StateR2 {stateR2_2_VAF:.2f} CC R2 {ccR2_2_VAF:.2f}\")\n",
    "ax.legend()\n",
    "hide_splines(ax)\n",
    "\n",
    "ax = fig.add_subplot(212)\n",
    "ax.plot(model3_pcs_trial[trial_num, :n_timesteps, latent_dim], c = 'orange', label = comparison.analyses[model64].run_name)\n",
    "ax.plot(pred3_trials[trial_num, :n_timesteps, latent_dim], c = 'orange', alpha=0.5, label = f\"From True\")\n",
    "ax.plot(pred3_cc_trials[trial_num, :n_timesteps, latent_dim], c = 'brown', label = f\"From Rates\")\n",
    "# ax.set_title(f\"State R2: {stateR2_3[latent_dim]:.2f}, CC R2: {ccR2_3[latent_dim]:.2f}\")\n",
    "ax.set_title(f\"StateR2 {stateR2_3_VAF:.2f} CC R2 {ccR2_3_VAF:.2f}\")\n",
    "ax.legend()\n",
    "# hide_splines(ax)\n",
    "\n",
    "fig.suptitle(f\"Predicting Latent Dimension {latent_dim+1}\")\n",
    "plt.savefig(\"latent_dim_pred_newCC.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "# Scatter the stateR2 vs. linear cycle consistency \n",
    "ax.scatter(metrics['state_r2'], metrics['rate_r2'], c = 'k', alpha = opacity)\n",
    "ax.scatter(metrics['state_r2'][model3], metrics['rate_r2'][model3], c = 'g', label = comparison.analyses[model3].run_name)\n",
    "ax.scatter(metrics['state_r2'][model8], metrics['rate_r2'][model8], c = 'blue', label = comparison.analyses[model8].run_name)\n",
    "ax.scatter(metrics['state_r2'][model64], metrics['rate_r2'][model64], c = 'orange', label = comparison.analyses[model64].run_name)\n",
    "\n",
    "ax.set_xlabel(\"State R2\")\n",
    "ax.set_ylabel(\"Rate R2\")\n",
    "ax.set_xlim([0.45, 1.0])\n",
    "ax.set_ylim([0.45, 1.0]) \n",
    "ax.legend(loc= 'lower left')\n",
    "plt.savefig(\"rateR2_vs_stateR2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "# Scatter the stateR2 vs. linear cycle consistency \n",
    "ax.scatter(metrics['cycle_con'], metrics['co-bps'], c = 'k', alpha = opacity)\n",
    "ax.scatter(metrics['cycle_con'][model3], metrics['co-bps'][model3], c = 'g', label = comparison.analyses[model3].run_name)\n",
    "ax.scatter(metrics['cycle_con'][model8], metrics['co-bps'][model8], c = 'blue', label = comparison.analyses[model8].run_name)\n",
    "ax.scatter(metrics['cycle_con'][model64], metrics['co-bps'][model64], c = 'orange', label = comparison.analyses[model64].run_name)\n",
    "\n",
    "ax.set_xlabel(\"Cycle-Con\")\n",
    "ax.set_ylabel(\"co-BPS\")\n",
    "# ax.set_xlim([0.45, 1.0])\n",
    "ax.set_ylim([0.06, .150]) \n",
    "ax.legend(loc= 'lower left')\n",
    "plt.savefig(\"coBPS_vs_cycleCon.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "# Scatter the stateR2 vs. linear cycle consistency \n",
    "ax.scatter(latent_sizes, metrics['cycle_con'], c = 'r', alpha = opacity)\n",
    "ax.set_xlabel(\"latent_sizes\")\n",
    "ax.set_ylabel(\"Cycle Consistency\")\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "# Scatter the stateR2 vs. linear cycle consistency \n",
    "ax.scatter(latent_sizes, metrics['state_r2'], c = 'r', alpha = opacity)\n",
    "ax.set_xlabel(\"latent_sizes\")\n",
    "ax.set_ylabel(\"StateR2\")\n",
    "\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = fig.add_subplot(111)\n",
    "# Scatter the stateR2 vs. linear cycle consistency \n",
    "ax.scatter(latent_sizes, metrics['mmd'], c = 'r', alpha = opacity)\n",
    "ax.set_xlabel(\"latent_sizes\")\n",
    "ax.set_ylabel(\"MMD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "build5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
